{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckGtwj0Eaoka",
        "outputId": "781c06d5-5a5a-44fc-f121-70f68ab3aa11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-WjAvEekaokb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, LSTM, Bidirectional, Reshape, Attention, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import zipfile\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/drive/MyDrive/Speech_Emotion_Recogntion/audio_src/combined_dataset_spectrograms_oversampled.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "print(f\"Fichiers extraits dans\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lViUJqnayjd",
        "outputId": "62aa3e32-616b-42df-e05c-7b3b4543e618"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fichiers extraits dans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VK_wWMERnFex"
      },
      "outputs": [],
      "source": [
        "original_spectrograms_dir = '/content/combined_dataset_spectrograms_oversampled/combined_dataset_spectrograms'\n",
        "augmented_spectrograms_dir = '/content/combined_dataset_spectrograms_oversampled/augmented_dataset_spectrograms'\n",
        "metrics_dir = '/content/drive/MyDrive/Speech_Emotion_Recogntion/metrics'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5qIl5SHnnFey",
        "outputId": "5ea456c4-22ec-4522-ebf1-493b5bab4032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble d'entraînement : (27089, 128, 128, 3), (27089, 7)\n",
            "Ensemble de validation : (4025, 128, 128, 3), (4025, 7)\n",
            "Ensemble de test : (4025, 128, 128, 3), (4025, 7)\n"
          ]
        }
      ],
      "source": [
        "# Dictionnaire pour mapper les émotions à des indices\n",
        "emotion_to_index = {\n",
        "    \"angry\": 0,\n",
        "    \"happy\": 1,\n",
        "    \"sad\": 2,\n",
        "    \"neutral\": 3,\n",
        "    \"fearful\": 4,\n",
        "    \"disgust\": 5,\n",
        "    \"surprise\": 6,\n",
        "}\n",
        "\n",
        "# Fonction pour charger les fichiers et leurs labels\n",
        "def load_data(spectrograms_dir, emotion_to_index):\n",
        "    images = []\n",
        "    labels = []\n",
        "    all_files = [file for file in os.listdir(spectrograms_dir) if file.endswith(\".png\")]\n",
        "\n",
        "    for file_name in all_files:\n",
        "        file_path = os.path.join(spectrograms_dir, file_name)\n",
        "\n",
        "        # Charger l'image et la redimensionner\n",
        "        img = Image.open(file_path).convert(\"RGB\")\n",
        "        img = img.resize((128, 128))\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        images.append(img_array)\n",
        "\n",
        "        # Extraire l'étiquette à partir du nom du fichier\n",
        "        emotion = file_name.split(\"_\")[1]\n",
        "        label = emotion_to_index.get(emotion, -1)\n",
        "        if label == -1:\n",
        "            raise ValueError(f\"Émotion inconnue dans le fichier : {file_name}\")\n",
        "\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Charger les données originales\n",
        "original_images, original_labels = load_data(original_spectrograms_dir, emotion_to_index)\n",
        "\n",
        "# Charger les données augmentées\n",
        "augmented_images, augmented_labels = load_data(augmented_spectrograms_dir, emotion_to_index)\n",
        "\n",
        "# Normaliser les images\n",
        "original_images = original_images / 255.0\n",
        "augmented_images = augmented_images / 255.0\n",
        "\n",
        "# Encodage One-hot des labels\n",
        "num_classes = len(emotion_to_index)\n",
        "original_labels_one_hot = to_categorical(original_labels, num_classes=num_classes)\n",
        "augmented_labels_one_hot = to_categorical(augmented_labels, num_classes=num_classes)\n",
        "\n",
        "# Séparer les données originales en ensemble d'entraînement, de validation et de test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    original_images, original_labels_one_hot, test_size=0.3, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Ajouter les données augmentées uniquement à l'ensemble d'entraînement\n",
        "X_train = np.concatenate((X_train, augmented_images), axis=0)\n",
        "y_train = np.concatenate((y_train, augmented_labels_one_hot), axis=0)\n",
        "\n",
        "# Mélanger les ensembles d'entraînement\n",
        "shuffle_indices = np.random.permutation(len(X_train))\n",
        "X_train = X_train[shuffle_indices]\n",
        "y_train = y_train[shuffle_indices]\n",
        "\n",
        "# Résumé des ensembles\n",
        "print(f\"Ensemble d'entraînement : {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Ensemble de validation : {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Ensemble de test : {X_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pe8VFuyaaokc"
      },
      "outputs": [],
      "source": [
        "def create_cnn_blstm_with_attention_model(num_classes):\n",
        "    inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "    # Block 1: CNN Layers\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Flatten\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    # Reshape for BLSTM\n",
        "    x = Reshape((8, 32))(x)\n",
        "\n",
        "    # BLSTM Layers\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Attention Mechanism (Self-Attention)\n",
        "    query = Dense(128, activation='relu')(x)\n",
        "    value = Dense(128, activation='relu')(x)\n",
        "    attention_output = layers.Attention()([query, value])\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = Flatten()(attention_output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def create_no_cnn_model(num_classes):\n",
        "    inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "    # Suppression du CNN, entrée directe pour la BLSTM\n",
        "    x = Flatten()(inputs)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Reshape((8, 32))(x)\n",
        "\n",
        "    # BLSTM + Attention\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    query = Dense(128, activation='relu')(x)\n",
        "    value = Dense(128, activation='relu')(x)\n",
        "    attention_output = layers.Attention()([query, value])\n",
        "\n",
        "    x = Flatten()(attention_output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def create_no_blstm_model(num_classes):\n",
        "    inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "    # CNN uniquement\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def create_no_attention_model(num_classes):\n",
        "    inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "    # CNN\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # BLSTM sans Attention\n",
        "    x = Reshape((8, 32))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=False))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def create_no_dropout_model(num_classes):\n",
        "    inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "    # Block 1: CNN Layers sans Dropout\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Flatten\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "\n",
        "    # Reshape for BLSTM\n",
        "    x = Reshape((8, 32))(x)\n",
        "\n",
        "    # BLSTM Layers\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "\n",
        "    # Attention Mechanism (Self-Attention)\n",
        "    query = Dense(128, activation='relu')(x)\n",
        "    value = Dense(128, activation='relu')(x)\n",
        "    attention_output = layers.Attention()([query, value])\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = Flatten()(attention_output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_no_regularization_model(num_classes):\n",
        "    inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "    # Block 1: CNN Layers sans régularisation\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Flatten\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    # Reshape for BLSTM\n",
        "    x = Reshape((8, 32))(x)\n",
        "\n",
        "    # BLSTM Layers\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Attention Mechanism (Self-Attention)\n",
        "    query = Dense(128, activation='relu')(x)\n",
        "    value = Dense(128, activation='relu')(x)\n",
        "    attention_output = layers.Attention()([query, value])\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = Flatten()(attention_output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"CNN_BLSTM_with_attention_V3_ablation_oversampled_dataset\"\n",
        "metrics_dir = os.path.join(metrics_dir, model_name)\n",
        "os.makedirs(metrics_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "WZi5tkDUXsVo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def save_training_plots(history, model_metrics_dir):\n",
        "    # Loss plot\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(history['loss'], label='Training Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.title(\"Loss Evolution\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(model_metrics_dir, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(\"Accuracy Evolution\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(model_metrics_dir, \"accuracy_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def save_confusion_matrix(model, X_test, y_test, model_metrics_dir, emotion_labels):\n",
        "    # Prédictions sur les données de test\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)  # Convertir les probabilités en classes\n",
        "    y_true = np.argmax(y_test, axis=1)  # Convertir les labels one-hot en indices de classes\n",
        "\n",
        "    # Générer la matrice de confusion\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=emotion_labels)\n",
        "\n",
        "    # Afficher et sauvegarder la matrice de confusion\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    disp.plot(cmap='Blues', values_format='d', ax=plt.gca())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.savefig(os.path.join(model_metrics_dir, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def train_and_evaluate_model(model_fn, model_name, metrics_dir):\n",
        "    model = model_fn(num_classes)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[early_stopping, lr_scheduler],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"{model_name} - Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "    # Créer le répertoire pour stocker les métriques\n",
        "    model_metrics_dir = os.path.join(metrics_dir, model_name)\n",
        "    os.makedirs(model_metrics_dir, exist_ok=True)\n",
        "\n",
        "    # Sauvegarder les courbes et la matrice de confusion\n",
        "    save_training_plots(history.history, model_metrics_dir)\n",
        "    save_confusion_matrix(model, X_test, y_test, model_metrics_dir, emotion_to_index.keys())\n",
        "\n",
        "    return history.history, test_loss, test_accuracy\n",
        "\n",
        "results = {}\n",
        "\n",
        "models_to_test = {\n",
        "    # \"No CNN\": create_no_cnn_model,\n",
        "    # \"No BLSTM\": create_no_blstm_model,\n",
        "    \"No Attention\": create_no_attention_model,\n",
        "    # \"No Dropout\": create_no_dropout_model,\n",
        "    # \"No Regularization\": create_no_regularization_model\n",
        "}\n",
        "\n",
        "# Utilisation de tqdm pour afficher la progression\n",
        "for name, model_fn in tqdm(models_to_test.items(), desc=\"Ablation Tests\"):\n",
        "    history, loss, accuracy = train_and_evaluate_model(model_fn, name, metrics_dir)\n",
        "    results[name] = {\"loss\": loss, \"accuracy\": accuracy}\n"
      ],
      "metadata": {
        "id": "PSIiL-4iRZwE",
        "outputId": "139f72d6-e7cf-4c1c-82a9-4f4a8412e15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ablation Tests:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The total size of the tensor must be unchanged. Received: input_shape=(32, 32, 64), target_shape=(8, 32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-365e5f7c61c6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# Utilisation de tqdm pour afficher la progression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_to_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Ablation Tests\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-365e5f7c61c6>\u001b[0m in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model_fn, model_name, metrics_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     model.compile(optimizer='adam',\n\u001b[1;32m     49\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c99227a902df>\u001b[0m in \u001b[0;36mcreate_no_attention_model\u001b[0;34m(num_classes)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# BLSTM sans Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation_utils.py\u001b[0m in \u001b[0;36mcompute_reshape_output_shape\u001b[0;34m(input_shape, newshape, newshape_arg_name)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munknown_dim_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0;34m\"The total size of the tensor must be unchanged. Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;34mf\"input_shape={input_shape}, {newshape_arg_name}={newshape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The total size of the tensor must be unchanged. Received: input_shape=(32, 32, 64), target_shape=(8, 32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrdmJSGKaoke"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(6, 5))\n",
        "\n",
        "# plt.plot(history.history['loss'], label='Training Loss')\n",
        "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "# plt.title(\"Loss Evolution\")\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend()\n",
        "# plt.savefig(os.path.join(model_metrics_dir, \"loss_curve.png\"))\n",
        "# plt.close()\n",
        "\n",
        "# plt.figure(figsize=(6, 5))\n",
        "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "# plt.title(\"Accuracy Evolution\")\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.legend()\n",
        "# plt.savefig(os.path.join(model_metrics_dir, \"accuracy_curve.png\"))\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Prédictions sur les données de test\n",
        "# y_pred = model.predict(X_test)\n",
        "# y_pred_classes = np.argmax(y_pred, axis=1)  # Convertir les probabilités en classes\n",
        "# y_true = np.argmax(y_test, axis=1)  # Convertir les labels one-hot en indices de classes\n",
        "\n",
        "# # Générer la matrice de confusion\n",
        "# conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=emotion_to_index.keys())\n",
        "\n",
        "# # Afficher et sauvegarder la matrice de confusion\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# disp.plot(cmap='Blues', values_format='d', ax=plt.gca())  # Utiliser les valeurs entières pour la matrice\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "# plt.savefig(os.path.join(model_metrics_dir, \"confusion_matrix.png\"))\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "MojXjWu9dQbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# emotion_counts = {emotion: 0 for emotion in emotion_to_index.keys()}\n",
        "# for label in original_labels:\n",
        "#     emotion_name = list(emotion_to_index.keys())[list(emotion_to_index.values()).index(label)]\n",
        "#     emotion_counts[emotion_name] += 1\n",
        "\n",
        "# emotions = list(emotion_counts.keys())\n",
        "# counts = list(emotion_counts.values())\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.bar(emotions, counts, color='skyblue', edgecolor='black')\n",
        "# plt.title(\"Répartition des émotions sélectionnées\", fontsize=16)\n",
        "# plt.xlabel(\"Émotions\", fontsize=14)\n",
        "# plt.ylabel(\"Nombre d'instances\", fontsize=14)\n",
        "# plt.xticks(rotation=45, fontsize=12)\n",
        "# plt.yticks(fontsize=12)\n",
        "\n",
        "# for i, count in enumerate(counts):\n",
        "#     plt.text(i, count + 0.5, str(count), ha='center', fontsize=12)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "2Ql7mnmpniwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}