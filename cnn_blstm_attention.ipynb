{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Bidirectional, Dropout, Reshape, Attention\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    spectrograms_dir = \"/content/drive/MyDrive/audio_representations/RAVDESS/spectrograms\"\n",
    "else :\n",
    "    spectrograms_dir = \"audio_representations/spectrograms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for file_name in os.listdir(spectrograms_dir):\n",
    "    if file_name.endswith(\".png\"):\n",
    "        file_path = os.path.join(spectrograms_dir, file_name)\n",
    "\n",
    "        # Convert to numpy\n",
    "        img = Image.open(file_path).convert(\"RGB\")\n",
    "        img = img.resize((256, 256))\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        images.append(img_array)\n",
    "\n",
    "        label = int(file_name.split(\"-\")[2]) - 1\n",
    "        labels.append(label)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize\n",
    "images = images / 255.0\n",
    "\n",
    "# One hot\n",
    "num_classes = len(np.unique(labels))\n",
    "labels_one_hot = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels_one_hot, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Ensemble d'entra√Ænement : {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Ensemble de validation : {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Ensemble de test : {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_blstm_attention_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # CNN Part\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten the output from CNN to pass into LSTM\n",
    "    model.add(Flatten())  # Flatten, if you want to maintain this approach for some reason\n",
    "\n",
    "    # Reshape for LSTM layer\n",
    "    model.add(Reshape((1, -1)))  # Reshape it to (batch_size, time_steps, features)\n",
    "\n",
    "    # BLSTM Part\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))  # LSTM with return_sequences=True for attention layer\n",
    "\n",
    "    # Attention Layer\n",
    "    model.add(Attention())  # Attention mechanism here\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Final output layer\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 3)  # 3 channels (RGB)\n",
    "model = create_cnn_blstm_attention_model(input_shape, num_classes)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss on the test set : {test_loss}\")\n",
    "print(f\"Accuracy on the test set : {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/content/drive/MyDrive/models/cnn_blstm_attention_ravdess_spectrograms'\n",
    "\n",
    "model.save(save_path + \"/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Loss Evolution\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_path, \"loss_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Accuracy Evolution\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_path, \"accuracy_curve.png\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = [\n",
    "    \"Neutral\", \"Calm\", \"Happy\", \"Sad\", \"Angry\",\n",
    "    \"Fearful\", \"Disgust\", \"Surprised\"\n",
    "]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=conf_matrix,\n",
    "    display_labels=emotion_labels\n",
    ")\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix CNN-BLSTM with attention Spectrograms\")\n",
    "conf_matrix_path = os.path.join(save_path, \"confusion_matrix.png\")\n",
    "plt.savefig(conf_matrix_path)\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
